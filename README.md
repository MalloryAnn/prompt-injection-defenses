# prompt-injection-defenses

reference github: https://github.com/tldrsec/prompt-injection-defenses?tab=readme-ov-file

Notes:

## Starting with Blast Reduction: i did research and think we should do this firsta nd then guardrails

-follow installation instrucitons

-test it/ run it

-start paper

Student Tasks

o Use provided datasets or small test cases.

## Body Paragraphs

Must show:

• What problem the tool solves

• How LLMs are used

• Input → processing → output

• At least one meaningful example

Walkthrough Report (4–6 pages, PDF)

## Body Paragraphs

Sections:

Project Overview

Security Problem Addressed

Architecture & Workflow

LLM Usage (model, prompts, fine-tuning, embeddings, etc.)

Strengths & Limitations

Reproducibility Notes
